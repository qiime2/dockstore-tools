# 
# Copyright (c) 2024, QIIME 2 development team.
# 
# Distributed under the terms of the Modified BSD License. (SPDX: BSD-3-Clause)
# 
# 
# This template was automatically generated by:
#     q2dataflow wdl (version: 0.2.0)
# for:
#     qiime2 (version: 2024.2.0)
# 


version 1.0

struct qiime2_longitudinal_feature_volatility_params {
    File table
    Array[File] q2wdl_metafile_metadata
    String state_column
    String? individual_id_column
    Int cv
    Int? random_state
    Int n_jobs
    Int n_estimators
    String estimator
    Boolean parameter_tuning
    String missing_samples
    String? importance_threshold
    String feature_count
    String filtered_table
    String feature_importance
    String volatility_plot
    String accuracy_results
    String sample_estimator
}

task qiime2_longitudinal_feature_volatility {

    input {
        File table
        Array[File] q2wdl_metafile_metadata
        String state_column
        String? individual_id_column
        Int cv = 5
        Int? random_state
        Int n_jobs = 1
        Int n_estimators = 100
        String estimator = "RandomForestRegressor"
        Boolean parameter_tuning = false
        String missing_samples = "error"
        String? importance_threshold
        String feature_count = '100'
        String filtered_table
        String feature_importance
        String volatility_plot
        String accuracy_results
        String sample_estimator
    }

    qiime2_longitudinal_feature_volatility_params task_params = object {
        table: table,
        q2wdl_metafile_metadata: q2wdl_metafile_metadata,
        state_column: state_column,
        individual_id_column: individual_id_column,
        cv: cv,
        random_state: random_state,
        n_jobs: n_jobs,
        n_estimators: n_estimators,
        estimator: estimator,
        parameter_tuning: parameter_tuning,
        missing_samples: missing_samples,
        importance_threshold: importance_threshold,
        feature_count: feature_count,
        filtered_table: filtered_table,
        feature_importance: feature_importance,
        volatility_plot: volatility_plot,
        accuracy_results: accuracy_results,
        sample_estimator: sample_estimator
    }

    command {
        q2dataflow wdl run longitudinal feature_volatility ~{write_json(task_params)}
    }

    output {
        File filtered_table_file = "~{filtered_table}"
        File feature_importance_file = "~{feature_importance}"
        File volatility_plot_file = "~{volatility_plot}"
        File accuracy_results_file = "~{accuracy_results}"
        File sample_estimator_file = "~{sample_estimator}"
    }

}


workflow wkflw_qiime2_longitudinal_feature_volatility {
input {
        File table
        Array[File] q2wdl_metafile_metadata
        String state_column
        String? individual_id_column
        Int cv = 5
        Int? random_state
        Int n_jobs = 1
        Int n_estimators = 100
        String estimator = "RandomForestRegressor"
        Boolean parameter_tuning = false
        String missing_samples = "error"
        String? importance_threshold
        String feature_count = '100'
        String filtered_table
        String feature_importance
        String volatility_plot
        String accuracy_results
        String sample_estimator
    }

    call qiime2_longitudinal_feature_volatility {
        input: table=table, q2wdl_metafile_metadata=q2wdl_metafile_metadata, state_column=state_column, individual_id_column=individual_id_column, cv=cv, random_state=random_state, n_jobs=n_jobs, n_estimators=n_estimators, estimator=estimator, parameter_tuning=parameter_tuning, missing_samples=missing_samples, importance_threshold=importance_threshold, feature_count=feature_count, filtered_table=filtered_table, feature_importance=feature_importance, volatility_plot=volatility_plot, accuracy_results=accuracy_results, sample_estimator=sample_estimator
    }

}
